# plugins used in this pipeline:
#   + logstash-input-udp
#   + logstash-codec-netflow
#   + logstash-filter-mutate
#   + logstash-filter-ruby
#   + logstash-filter-dns
#   + logstash-output-elasticsearch
#   + logstash-output-file
#
# index template settings:
#   + Data stream: "true"
#   + Priority: "200"
#   + Component templates: "as needed ..."
#   + Index settings: "specify ILM Policy"
#
# ToDo's:
#   + sampled netflow data possible with this pipeline?
#   + create component template for field mapping
#   + aggregation with elastic rollup jobs
#   + use metric instead of logs

# ~~~~~~~~~~~~~~~~~~~
# >> Netflow Input <<
# ~~~~~~~~~~~~~~~~~~~
input {
  udp {
    port => 9996
    codec => "netflow"
    receive_buffer_bytes => 16777216
    workers => 16
  }
}

# ~~~~~~~~~~~~~~~~~~~~
# >> Netflow Filter <<
# ~~~~~~~~~~~~~~~~~~~~
filter {
#  # Automatically caclulate sampled netflow data
#  if [netflow][sampling_interval] {
#    if [netflow][in_bytes] and [netflow][sampling_interval] > 0 {
#      ruby {
#        code => "
#          event.set('[netflow][in_bytes]', event.get('[netflow][in_bytes]').to_i * event.get('[netflow][sampling_interval]').to_i)
#        "
#      }
#    }
#    if [netflow][in_pkts] and [netflow][sampling_interval] > 0 {
#      ruby {
#        code => "
#          event.set('[netflow][in_pkts]', event.get('[netflow][in_pkts]').to_i * event.get('[netflow][sampling_interval]').to_i)
#        "
#      }
#    }
#  }

  # Manually caclulate sampled netflow data
  if [host] == "138.22.203.117" or [host] == "138.22.203.118" or [host] == "138.22.194.16" {
    if [netflow][in_bytes] and [netflow][in_bytes] > 0 {
      ruby {
        code => "
          event.set('[netflow][in_bytes]', event.get('[netflow][in_bytes]').to_i * 512)
        "
      }
    }
    if [netflow][in_pkts] and [netflow][in_pkts] > 0 {
      ruby {
        code => "
          event.set('[netflow][in_pkts]', event.get('[netflow][in_pkts]').to_i * 512)
        "
      }
    }
  }

  # Add flow count for further calculation in kibana - needed because of different sampling rates
  if [host] == "138.22.203.117" or [host] == "138.22.203.118" or [host] == "138.22.194.16" {
    mutate {
      add_field => { "[netflow][in_flows]" => "512" }
    }
  }
  else {
    mutate {
      add_field => { "[netflow][in_flows]" => "1" }
    }
  }

  # Change IP to FQDN
  dns {
    failed_cache_size => 100
    failed_cache_ttl => 3600
    hit_cache_size => 100
    hit_cache_ttl => 3600
    reverse => ["host"]
    action => "replace"
  }

  # Parse correct Timestamp
  date {
    match => [ "[netflow][last_switched]", "ISO8601" ]
  }

  # Add event.dataset
  mutate {
    add_field => { "[event][dataset]" => "netflow"  }
  }
}

# ~~~~~~~~~~~~~~~~~~~~
# >> Elastic Output <<
# ~~~~~~~~~~~~~~~~~~~~
output {
  if ![tags] {
    # on success => write to elastic
    elasticsearch {
      hosts => ["https://127.0.0.1:9200"]
      index => "metrics-%{[event][dataset]}-prod"
      action => "create"
      user => "elastic"
      password => "Cisco123"
      ssl => true
      cacert => "/etc/ssl/certs/elasticsearch-ca.pem"
    }
  }
  else {
    # on failure => write to logfile
    file {
      path => "/var/log/logstash/pipeline.log"
    }
  }
}
